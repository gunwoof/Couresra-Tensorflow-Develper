{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQjHqsmTAVLU"
      },
      "source": [
        "# Week 3: Improve MNIST with Convolutions\n",
        "\n",
        "In the videos you looked at how you would improve Fashion MNIST using Convolutions. For this exercise see if you can improve MNIST to 99.5% accuracy or more by adding only a single convolutional layer and a single MaxPooling 2D layer to the model from the  assignment of the previous week. \n",
        "\n",
        "You should stop training once the accuracy goes above this amount. It should happen in less than 10 epochs, so it's ok to hard code the number of epochs for training, but your training must end once it hits the above metric. If it doesn't, then you'll need to redesign your callback.\n",
        "\n",
        "When 99.5% accuracy has been hit, you should print out the string \"Reached 99.5% accuracy so cancelling training!\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**concolution을 통하여 기존모델보다 향상된 모델을 만들어라**\n",
        "\n",
        "*   하나의 convolutional layer과 MaxPooling 2D layer을 사용해라\n",
        "*   10ephoch를 넘기기 전에 callback(정확도 99.5기준)해라\n",
        "\n"
      ],
      "metadata": {
        "id": "ZMW3D_B-hvS6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZpztRwBouwYp",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3Y66I6xS5x4"
      },
      "source": [
        "## Load the data\n",
        "\n",
        "Begin by loading the data. A couple of things to notice:\n",
        "\n",
        "- The file `mnist.npz` is already included in the current workspace under the `data` directory. By default the `load_data` from Keras accepts a path relative to `~/.keras/datasets` but in this case it is stored somewhere else, as a result of this, you need to specify the full path.\n",
        "\n",
        "- `load_data` returns the train and test sets in the form of the tuples `(x_train, y_train), (x_test, y_test)` but in this exercise you will be needing only the train set so you can ignore the second tuple."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   mnist 파일을 사용해라\n",
        "*   보통 (x_train, y_train), (x_test, ytest) 2개의 튜플을 사용하지만 여기서는 train set만 사용하기 때문에 두 번째''을 사용하여 저장한다"
      ],
      "metadata": {
        "id": "hUgJYUnmiqcX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "CYVcZwQpS5x5"
      },
      "outputs": [],
      "source": [
        "# Load the data\n",
        "\n",
        "# Get current working directory\n",
        "current_dir = os.getcwd() \n",
        "\n",
        "# Append data/mnist.npz to the previous path to get the full path\n",
        "data_path = os.path.join(current_dir, \"mnist.npz\") \n",
        "\n",
        "# Get only training set\n",
        "(training_images, training_labels), _ = tf.keras.datasets.mnist.load_data(path=data_path) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SN988BlkS5x6"
      },
      "source": [
        "## Pre-processing the data\n",
        "\n",
        "One important step when dealing with image data is to preprocess the data. During the preprocess step you can apply transformations to the dataset that will be fed into your convolutional neural network.\n",
        "\n",
        "Here you will apply two transformations to the data:\n",
        "- Reshape the data so that it has an extra dimension. The reason for this \n",
        "is that commonly you will use 3-dimensional arrays (without counting the batch dimension) to represent image data. The third dimension represents the color using RGB values. This data might be in black and white format so the third dimension doesn't really add any additional information for the classification process but it is a good practice regardless.\n",
        "\n",
        "\n",
        "- Normalize the pixel values so that these are values between 0 and 1. You can achieve this by dividing every value in the array by the maximum.\n",
        "\n",
        "Remember that these tensors are of type `numpy.ndarray` so you can use functions like [reshape](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html) or [divide](https://numpy.org/doc/stable/reference/generated/numpy.divide.html) to complete the `reshape_and_normalize` function below:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   data processing은 중요한 단계이다\n",
        "*   보통은 3차원을 사용하지만 이번 프로젝트에서는 흑백사진이라 1차원만 사용한다\n",
        "*   noamalization 적용 -> 배열의 최대값으로 나눔\n",
        "*   numpy.array(벡터화)를 사용해야 reshape, divide method를 사용할 수 있다 \n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "kIBs1SK_9JTx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   \"rank 1 array\"를 사용하지 말고 \"vector를 사용해라\n",
        "ex) np.array.shape(1,3)\n",
        "*   np.array.reshape() : 차원을 바꿈\n",
        "*   벡터에 broad cast를 사용하여 for문 없이 scalar연산을 할 수 있다\n",
        "\n"
      ],
      "metadata": {
        "id": "kDGzBJxY-_3R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "1oAmr7d5S5x7"
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: reshape_and_normalize\n",
        "\n",
        "def reshape_and_normalize(images):\n",
        "    \n",
        "    ### START CODE HERE\n",
        "\n",
        "    # Reshape the images to add an extra dimension\n",
        "    images = images.reshape([60000, 28, 28, 1]) # [원소개수, 행, 열, 차원]\n",
        "   \n",
        "    \n",
        "    # Normalize pixel values\n",
        "    images = images / 255.0;\n",
        "    \n",
        "    ### END CODE HERE\n",
        "\n",
        "    return images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqE7ewnVS5x8"
      },
      "source": [
        "Test your function with the next cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDlAWbYMS5x9",
        "outputId": "31e01f37-8c23-4983-8da4-a8b30f902f15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum pixel value after normalization: 1.0\n",
            "\n",
            "Shape of training set after reshaping: (60000, 28, 28, 1)\n",
            "\n",
            "Shape of one image after reshaping: (28, 28, 1)\n"
          ]
        }
      ],
      "source": [
        "# Reload the images in case you run this cell multiple times\n",
        "(training_images, _), _ = tf.keras.datasets.mnist.load_data(path=data_path) \n",
        "\n",
        "# Apply your function\n",
        "training_images = reshape_and_normalize(training_images)\n",
        "\n",
        "print(f\"Maximum pixel value after normalization: {np.max(training_images)}\\n\")\n",
        "print(f\"Shape of training set after reshaping: {training_images.shape}\\n\")\n",
        "print(f\"Shape of one image after reshaping: {training_images[0].shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhgnoWN6S5x_"
      },
      "source": [
        "**Expected Output:**\n",
        "```\n",
        "Maximum pixel value after normalization: 1.0\n",
        "\n",
        "Shape of training set after reshaping: (60000, 28, 28, 1)\n",
        "\n",
        "Shape of one image after reshaping: (28, 28, 1)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYvIhHZvS5yA"
      },
      "source": [
        "## Defining your callback\n",
        "\n",
        "Now complete the callback that will ensure that training will stop after an accuracy of 99.5% is reached:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   정확도 99.5를 기준으로 하는 callback함수 정의\n"
      ],
      "metadata": {
        "id": "rtLU9kAQSvZW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "fMd_UnwRS5yA"
      },
      "outputs": [],
      "source": [
        "# GRADED CLASS: myCallback\n",
        "### START CODE HERE\n",
        "\n",
        "# Remember to inherit from the correct class\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    # Define the method that checks the accuracy at the end of each epoch\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if (logs.get('accuracy') >= 0.995):\n",
        "          print('\\nReached 99.5% accuracy so cancelling training!')\n",
        "          self.model.stop_training = True\n",
        "    pass\n",
        "\n",
        "### END CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akatrBH_S5yB"
      },
      "source": [
        "## Convolutional Model\n",
        "\n",
        "Finally, complete the `convolutional_model` function below. This function should return your convolutional neural network.\n",
        "\n",
        "**Your model should achieve an accuracy of 99.5% or more before 10 epochs to pass this assignment.**\n",
        "\n",
        "**Hints:**\n",
        "- You can try any architecture for the network but try to keep in mind you don't need a complex one. For instance, only one convolutional layer is needed. \n",
        "\n",
        "- In case you need extra help you can check out an architecture that works pretty well at the end of this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   10번 전에 callback해라\n",
        "*   convolutional layer을 한번 사용해라\n",
        "\n"
      ],
      "metadata": {
        "id": "83mJdAECTFT8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "tags": [
          "graded"
        ],
        "id": "mmQY3lfnS5yC"
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: convolutional_model\n",
        "def convolutional_model():\n",
        "    ### START CODE HERE\n",
        "\n",
        "    # Define the model\n",
        "    model = tf.keras.models.Sequential([ \n",
        "        tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ]) \n",
        "\n",
        "    ### END CODE HERE\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', \n",
        "                  loss='sparse_categorical_crossentropy', \n",
        "                  metrics=['accuracy']) \n",
        "        \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRXBuxbqS5yC",
        "outputId": "661639fd-4c59-404b-a0d8-2a624d9a0b4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 40s 21ms/step - loss: 0.1442 - accuracy: 0.9567\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 41s 22ms/step - loss: 0.0492 - accuracy: 0.9848\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 40s 21ms/step - loss: 0.0308 - accuracy: 0.9903\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 41s 22ms/step - loss: 0.0200 - accuracy: 0.9934\n",
            "Epoch 5/10\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.0125 - accuracy: 0.9961\n",
            "Reached 99.5% accuracy so cancelling training!\n",
            "1875/1875 [==============================] - 42s 22ms/step - loss: 0.0125 - accuracy: 0.9961\n"
          ]
        }
      ],
      "source": [
        "# Save your untrained model\n",
        "model = convolutional_model()\n",
        "\n",
        "# Instantiate the callback class\n",
        "callbacks = myCallback()\n",
        "\n",
        "# Train your model (this can take up to 5 minutes)\n",
        "history = model.fit(training_images, training_labels, epochs=10, callbacks=[callbacks])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8C_JRsdS5yD"
      },
      "source": [
        "If you see the message that you defined in your callback printed out after less than 10 epochs it means your callback worked as expected. You can also double check by running the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AweEqFXS5yD",
        "outputId": "e3bc765d-9d11-4f06-d2b9-f4109f2f77c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your model was trained for 5 epochs\n"
          ]
        }
      ],
      "source": [
        "print(f\"Your model was trained for {len(history.epoch)} epochs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTEds3UuS5yG"
      },
      "source": [
        "## Need more help?\n",
        "\n",
        "Run the following cell to see an architecture that works well for the problem at hand:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9r_M-YpnS5yH",
        "outputId": "2b53663e-6c26-4abd-fe6a-abc1d5341507"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "   - A Conv2D layer with 32 filters, a kernel_size of 3x3, ReLU activation function and an input shape that matches that of every image in the training set\n",
            "   - A MaxPooling2D layer with a pool_size of 2x2\n",
            "   - A Flatten layer with no arguments\n",
            "   - A Dense layer with 128 units and ReLU activation function\n",
            "   - A Dense layer with 10 units and softmax activation function\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# WE STRONGLY RECOMMEND YOU TO TRY YOUR OWN ARCHITECTURES FIRST\n",
        "# AND ONLY RUN THIS CELL IF YOU WISH TO SEE AN ANSWER\n",
        "\n",
        "import base64\n",
        "\n",
        "encoded_answer = \"CiAgIC0gQSBDb252MkQgbGF5ZXIgd2l0aCAzMiBmaWx0ZXJzLCBhIGtlcm5lbF9zaXplIG9mIDN4MywgUmVMVSBhY3RpdmF0aW9uIGZ1bmN0aW9uIGFuZCBhbiBpbnB1dCBzaGFwZSB0aGF0IG1hdGNoZXMgdGhhdCBvZiBldmVyeSBpbWFnZSBpbiB0aGUgdHJhaW5pbmcgc2V0CiAgIC0gQSBNYXhQb29saW5nMkQgbGF5ZXIgd2l0aCBhIHBvb2xfc2l6ZSBvZiAyeDIKICAgLSBBIEZsYXR0ZW4gbGF5ZXIgd2l0aCBubyBhcmd1bWVudHMKICAgLSBBIERlbnNlIGxheWVyIHdpdGggMTI4IHVuaXRzIGFuZCBSZUxVIGFjdGl2YXRpb24gZnVuY3Rpb24KICAgLSBBIERlbnNlIGxheWVyIHdpdGggMTAgdW5pdHMgYW5kIHNvZnRtYXggYWN0aXZhdGlvbiBmdW5jdGlvbgo=\"\n",
        "encoded_answer = encoded_answer.encode('ascii')\n",
        "answer = base64.b64decode(encoded_answer)\n",
        "answer = answer.decode('ascii')\n",
        "\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Or9UvMyXS5yH"
      },
      "source": [
        "**Congratulations on finishing this week's assignment!**\n",
        "\n",
        "You have successfully implemented a CNN to assist you in the image classification task. Nice job!\n",
        "\n",
        "**Keep it up!**"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "main_language": "python"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}